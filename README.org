* CSVX
  A dependency-free tool that enables you to control how you
  tokenize, transform and handle char(s) separated values.

* Usage
  #+begin_src clojure :results silent
    (require '[csvx.core :as csvx])
    ;; Then you can use the defaults to parse csv files like this:
    (csvx/readx "resources/100-sales-records.csv")
    ;; Note that csvx/readx takes optional arg where you can pass in following
    ;; options: (listed values here are defaults if no option is given See src/csvx/core.clj
    ;; for details).
    {:encoding "UTF-8"
     :max-lines-to-read Integer/MAX_VALUE
     :line-tokenizer (fn [^String line]
		       (try (.split line ",")
			    (catch Exception e
			      (println :malformed-line line)
			      ;; (strace/print-stack-trace e) ;; handle exception here
                              nil)))
     :line-transformer #(map-indexed hash-map %)}
    #+end_src

# Say you have a giant json file that you need to parse into Clojure
# map, all you need to do is to to write line tokenizer and
# transformer like this:
#+begin_src clojure :results silent_
(defn decode-json [^String file-path]
  (readx file-path ;;"sample.json"
         {:max-lines-to-read 1
          :line-tokenizer (fn [line]
                            (map #(.split ^String % ":")
                                 (-> (clojure.string/replace line #"\{|\}" "")
                                     (.split ","))))
          :line-transformer (fn [line]
                              (reduce (fn [acc [f s]]
                                        (merge acc {(keyword (read-string f))
                                                    (read-string s)}))
                                      {}
                                      line))}))
#+end_src
